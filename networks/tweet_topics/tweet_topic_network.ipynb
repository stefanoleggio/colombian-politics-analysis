{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e30deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d493bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tweet topic data\n",
    "tweet_topic = pd.read_csv(\"../../../data/tweet_topic.csv\")\n",
    "\n",
    "# create topic dictionary\n",
    "topic_assign = pd.read_csv(\"../../../data/topic_dictionary.csv\")\n",
    "topic_dict = dict(zip(topic_assign['id_topic'], topic_assign['label']))\n",
    "\n",
    "# load all tweet data\n",
    "tweets = pd.read_csv(\"../../../data/tweets.csv\")\n",
    "tweets['hashtag'] = tweets['full_text'].apply(lambda x: re.findall(r'#(\\w+)', x))\n",
    "tweets[\"is_reply\"] = [int(~np.isnan(tweet)) for tweet in tweets[\"in_reply_twitter_id\"]]\n",
    "tweets = tweets.rename(columns = {'id':'id_tweet'})\n",
    "\n",
    "# load users\n",
    "users = pd.read_csv(\"../../../data/users.csv\")\n",
    "user_dict = dict(zip(users['userid'],users['username']))\n",
    "tweet_user_dict = dict(zip(tweets['id_tweet'],tweets['user_id']))\n",
    "\n",
    "# load hashtags\n",
    "tweet_hashtag = pd.read_csv(\"../../../data/tweet_hashtag.csv\")\n",
    "hashtag = pd.read_csv(\"../../../data/hashtag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdecc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the full topic assignment from the lda\n",
    "# topics are already processed and are between 1 and 10.\n",
    "with open('../../../ColombianPoliticsSentiment/final_lda_model/topic_assign_full.json') as f:\n",
    "    tweet_topics = [[(int(i[0]),int(i[1]),float(i[2])) for i in t] for t in json.load(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ed6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter topics with score > 20 and normalise scores\n",
    "filt_topics = [[j for j in b if j[2] > 0.2] for b in tweet_topics]\n",
    "\n",
    "# define edges between all tweets and topics \n",
    "edges = []\n",
    "for idx, t in enumerate(filt_topics):\n",
    "    score_sum = sum([i[2] for i in t])\n",
    "    edges += [(i[0],str(\"t_\"+str(i[1])),i[2]/score_sum) for i in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccbf713",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = tweets['id_tweet'][tweets['is_reply'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3da230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset edges for original tweets only\n",
    "edges_tweets_only = [i for i in edges if i[0] in tweet_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e2e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network between tweets and topics only for original tweets\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edges_tweets_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "209c7e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_1\n"
     ]
    }
   ],
   "source": [
    "# add main topic attribute to each node\n",
    "# create dictionary between tweet and respective main topic\n",
    "tweet_to_topic_dict = dict(zip(tweet_topic['id_tweet'],tweet_topic['id_topic']))\n",
    "adapt_topic_dict = dict(zip([\"t_\"+str(j) for j in range(1,11)],list(topic_dict.values())))\n",
    "\n",
    "# add attributes\n",
    "for i in G.nodes:\n",
    "    try: \n",
    "        G.nodes[i]['topic'] = adapt_topic_dict[i]\n",
    "        G.nodes[i]['main_topic'] = topic_dict[tweet_to_topic_dict[i]]\n",
    "        G.nodes[i]['author'] = user_dict[tweet_user_dict[i]]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52056d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tweet ids to create the nodes\n",
    "tweet_nodes = list(np.unique([j[0] for j in edges_tweets_only]))\n",
    "# project network on tweets\n",
    "tweet_proj = bipartite.weighted_projected_graph(G,nodes = tweet_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29c2beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341\n",
      "340638\n"
     ]
    }
   ],
   "source": [
    "print(len(tweet_proj.nodes()))\n",
    "print(len(tweet_proj.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "168cf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save networks\n",
    "nx.write_graphml(tweet_proj,\"projected_tweet_topic_network.graphml\")\n",
    "nx.write_graphml(G,\"tweet_topic_network.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
